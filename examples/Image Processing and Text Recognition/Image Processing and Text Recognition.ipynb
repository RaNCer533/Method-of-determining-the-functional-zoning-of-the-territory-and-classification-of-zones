{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from osgeo import gdal, ogr\n",
    "import easyocr\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point, shape, Polygon, LineString\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from shapely import LineString, MultiLineString, MultiPolygon\n",
    "import os\n",
    "\n",
    "def process_image(image_path: str, upper_left: tuple, upper_right: tuple, lower_left: tuple, lower_right: tuple):\n",
    "    try:\n",
    "        # Step 1: Load and blur the image\n",
    "        img = cv2.imread(image_path)  # Read the image from the specified path\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")  # Raise an error if the image is not found\n",
    "        #img = cv2.resize(img,(0,0),fx=0.3,fy=0.3)\n",
    "        blurred_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply Gaussian blur to the image to reduce noise\n",
    "        \n",
    "\n",
    "        blurred_img = cv2.GaussianBlur(blurred_img, (9, 9), cv2.BORDER_DEFAULT)\n",
    "        # Convert the blurred image from BGR to RGB color space\n",
    "        \n",
    "\n",
    "\n",
    "        # Convert image to pixel list and cluster using KMeans\n",
    "        pixels = blurred_img.reshape(-1, 3)  # Reshape the image to a 2D array of pixels\n",
    "        kmeans = KMeans(n_clusters=5)  # Initialize KMeans with 5 clusters\n",
    "        kmeans.fit(pixels)  # Fit the KMeans model to the pixel data\n",
    "        # Create a segmented image based on the cluster centers\n",
    "        segmented_img = kmeans.cluster_centers_[kmeans.labels_].reshape(blurred_img.shape).astype(np.uint8)\n",
    "\n",
    "        # Save the segmented image to a file\n",
    "        cv2.imwrite('segmented_image.tif', cv2.cvtColor(segmented_img, cv2.COLOR_RGB2BGR))\n",
    "        # Calculate width and height for GeoTIFF creation\n",
    "        width = upper_right[0] - upper_left[0]\n",
    "        height = upper_left[1] - lower_left[1]\n",
    "\n",
    "        # Create a GeoTIFF for the segmented image\n",
    "        driver = gdal.GetDriverByName('GTiff')  # Get the GeoTIFF driver\n",
    "        out_raster = driver.Create('segmented_image.tif', segmented_img.shape[1], segmented_img.shape[0], 3, gdal.GDT_Byte)\n",
    "        # Set the geographical transformation for the raster\n",
    "        out_raster.SetGeoTransform((upper_left[0], width / segmented_img.shape[1], 0, upper_left[1], 0, -height / segmented_img.shape[0]))\n",
    "\n",
    "        # Write each color band to the GeoTIFF\n",
    "        for i in range(3):\n",
    "            out_raster.GetRasterBand(i + 1).WriteArray(cv2.cvtColor(segmented_img, cv2.COLOR_RGB2BGR)[:, :, i])\n",
    "        out_raster.FlushCache()  # Save changes to the file\n",
    "        out_raster = None  # Close the raster dataset\n",
    "\n",
    "        # Rasterize the segmented image to vector format\n",
    "        raster_ds = gdal.Open('segmented_image.tif')  # Open the segmented raster dataset\n",
    "        if not raster_ds:\n",
    "            raise Exception(\"Failed to open raster dataset.\")  # Raise an error if opening fails\n",
    "\n",
    "        # Create a GeoJSON data source for the vector output\n",
    "        vector_ds = ogr.GetDriverByName('GeoJSON').CreateDataSource('file.geojson')\n",
    "        layer = vector_ds.CreateLayer('polygons', geom_type=ogr.wkbPolygon)  # Create a layer for polygons\n",
    "        # Polygonize the raster data into vector format\n",
    "        gdal.Polygonize(raster_ds.GetRasterBand(1), None, layer, -1, [], callback=None)\n",
    "        vector_ds = None  # Close the vector dataset\n",
    "        raster_ds = None  # Close the raster dataset\n",
    "\n",
    "        # Step 2: Text recognition\n",
    "        # Initialize the EasyOCR reader for Russian language\n",
    "        reader = easyocr.Reader(['ru'])\n",
    "        results = reader.readtext(img)\n",
    "\n",
    "        height, width, _ = img.shape\n",
    "        points = []\n",
    "\n",
    "        for (bbox, text, prob) in results:\n",
    "            top_left = bbox[0]  # Get the top-left corner of the bounding box\n",
    "            x_ratio = top_left[0] / width  # Calculate the x ratio\n",
    "            y_ratio = top_left[1] / height  # Calculate the y ratio\n",
    "            geo_x = upper_left[0] + (upper_right[0] - upper_left[0]) * x_ratio\n",
    "            geo_y = upper_left[1] + (lower_left[1] - upper_left[1]) * y_ratio\n",
    "            point = Point(geo_x, geo_y)  # Create a Point object for the coordinates\n",
    "            points.append({'geometry': point, 'name': text, 'probability': prob})  # Append point data to the list\n",
    "\n",
    "        text_points_gdf = gpd.GeoDataFrame(points)\n",
    "        text_points_gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "        def assign_landuse(text):\n",
    "            if text in [\"Т1Ж1\", \"Т2Ж1\", \"Т1Ж2-1\", \"Т1Ж2-2\", \"ТЖ-1\", \"ТЖ-1-2\", \"ТЖ-2\", \"ТЖ-2-1\", \"ТЖ-2-2\", \"ТЖ-2-3\", \"ТЖ-3\", \"ТЖ-4\", \"ТЖ-4-1\", \"ТЖ-5\", \"ТЖ-5-1\", \"ТЖ-6\", \"ТЖ-7\"]:\n",
    "                return \"Residential\"\n",
    "            elif text in [\"Т3Ж1\", \"Т3Ж2\", \"Т2ЖД2\", \"Т3ЖД3\"]:\n",
    "                return \"Mixed-use\"\n",
    "            elif text in [\"ТД1-3\", \"ТД2\", \"ТД3\", \"ТД-1\", \"ТД-1-1\", \"ТД-1-2\", \"ТД-4\", \"ТД-5\", \"ТД-6\", \"ТД-7\"]:\n",
    "                return \"Business\"\n",
    "            elif text in [\"ТР0-1\", \"ТР0-2\", \"ТР1\", \"ТР2\", \"ТР3-1\", \"ТР3-2\", \"ТР4\", \"ТР5-1\", \"ТР5-2\", \"ТР-1\", \"ТР-2\", \"ТР-3\", \"ТР-4\", \"ТР-5\", \"ТР-6\", \"ТР-7\"]:\n",
    "                return \"Recreation\"\n",
    "            elif text in [\"ТК1\", \"ТК2\", \"ТК3\", \"ТК\", \"ТК-1\", \"ТК-2\", \"ТЗН\", \"Т3Н-1\"]:\n",
    "                return \"Special\"\n",
    "            elif text in [\"ТП1\", \"ТП2\", \"ТП3\", \"ТП4\", \"ТПД1\", \"ТПД2\", \"ТП-1\", \"ТП-2\", \"ТП-3\", \"ТП-4\", \"ТП-5\"]:\n",
    "                return \"Industrial\"\n",
    "            elif text in [\"ТС1\", \"ТС-1\"]:\n",
    "                return \"Agriculture\"\n",
    "            elif text in [\"ТС1\", \"ТИ1-1\", \"ТИ1-2\", \"ТИ2\", \"ТИ3\", \"ТИ4\", \"ТУ\", \"ТИ-1\", \"ТИ-2\", \"ТТ-1\", \"ТТ-1-1\", \"ТТ-2\", \"ТТ-3\"]:\n",
    "                return \"Transport\"\n",
    "            else:\n",
    "                return None    \n",
    "\n",
    "        text_points_gdf['landuse'] = text_points_gdf['name'].apply(assign_landuse)\n",
    "\n",
    "        # Step 3: Process GeoJSON\n",
    "        with fiona.open('file.geojson', 'r') as source:  # Open the GeoJSON file for reading\n",
    "            geometries = []  # List to store geometries\n",
    "            attributes = []  # List to store attributes\n",
    "\n",
    "            # Iterate through each feature in the GeoJSON\n",
    "            for feature in source:\n",
    "                geom = shape(feature['geometry'])  # Convert geometry to a shapely object\n",
    "                attrs = feature['properties']  # Extract properties (attributes)\n",
    "                geometries.append(geom)  # Append geometry to the list\n",
    "                attributes.append(attrs)  # Append attributes to the list\n",
    "\n",
    "        # Create a GeoDataFrame from the attributes and geometries\n",
    "        filtered_geodata = gpd.GeoDataFrame(attributes, geometry=geometries)\n",
    "        filtered_geodata.set_crs(4326, inplace=True)  # Set the coordinate reference system to EPSG:4326\n",
    "        filtered_geodata.to_crs(3857, inplace=True)  # Transform to EPSG:3857 for area calculations\n",
    "        filtered_geodata.geometry = filtered_geodata.geometry.simplify(1)  # Simplify geometries\n",
    "        filtered_geodata['area'] = filtered_geodata.geometry.area  # Calculate area of each geometry\n",
    "\n",
    "        # Align the filter by area using the 25th percentile as a threshold\n",
    "        threshold = filtered_geodata['area'].quantile(0.25)\n",
    "        filtered_geodata = filtered_geodata[filtered_geodata['area'] > threshold]  # Filter geometries by area\n",
    "\n",
    "        # Iterate through filtered_geodata and retain only exterior boundaries of polygons with interiors\n",
    "        for index, row in filtered_geodata.iterrows():\n",
    "            geom = row['geometry']\n",
    "            if geom.interiors:  # Check if the geometry has interior boundaries\n",
    "                filtered_geodata.at[index, 'geometry'] = Polygon(geom.exterior.coords)  # Keep only the exterior\n",
    "\n",
    "        # Convert polygons to MultiLineString using _polygons_to_linestring function\n",
    "        def _polygons_to_linestring(geom):\n",
    "            def convert_polygon(polygon: Polygon):\n",
    "                lines = [LineString(polygon.exterior.coords)]  # Create line from exterior\n",
    "                lines.extend(LineString(p.coords) for p in polygon.interiors)  # Add lines from interiors\n",
    "                return lines\n",
    "            if geom.geom_type == \"Polygon\":\n",
    "                return MultiLineString(convert_polygon(geom))  # Convert single polygon to MultiLineString\n",
    "            if geom.geom_type == \"MultiPolygon\":\n",
    "                return MultiLineString(sum([convert_polygon(p) for p in geom.geoms], []))  # Convert MultiPolygon\n",
    "            return geom  # Return the geometry unchanged if not a polygon\n",
    "\n",
    "        # Combine geometries into new polygons with _combine_geometry function\n",
    "        def _combine_geometry(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "            crs = gdf.crs  # Get the coordinate reference system\n",
    "            polygons = polygonize(gdf[\"geometry\"].apply(_polygons_to_linestring).unary_union)  # Combine geometries\n",
    "            return gpd.GeoDataFrame(geometry=list(polygons), crs=crs)  # Return new GeoDataFrame\n",
    "\n",
    "        # Transform the GeoDataFrame back to the EPSG:4326 coordinate system\n",
    "        filtered_geodata = _combine_geometry(filtered_geodata)\n",
    "        filtered_geodata.to_crs(4326, inplace=True)\n",
    "\n",
    "        # Merge the filtered GeoDataFrame with another GeoDataFrame by intersection\n",
    "        merged_gdf = gpd.sjoin(filtered_geodata, text_points_gdf, how=\"left\", predicate=\"intersects\")\n",
    "        merged_gdf = merged_gdf.reset_index(drop=True)  # Reset index after merging\n",
    "\n",
    "        return filtered_geodata  \n",
    "    \n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        if os.path.exists('file.geojson'):\n",
    "            os.remove('file.geojson')\n",
    "\n",
    "        if os.path.exists('segmented_image.tif'):\n",
    "            os.remove('segmented_image.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Reddut\\Anaconda 3\\envs\\virtualenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "pzz = process_image('155519.png', \n",
    "                    (30.492358021,59.877292545), #59.877292545,30.492358021\n",
    "                    (30.594947179,59.875805700), #59.875805700,30.594947179\n",
    "                    (30.487330294,59.830103750), #59.830103750,30.487330294\n",
    "                    (30.591116544 ,59.830741884)) #59.830741884,30.591116544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "pzz.to_file('NOVO.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Reddut\\Anaconda 3\\envs\\virtualenv\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "Cell \u001b[1;32mIn[2], line 227\u001b[0m, in \u001b[0;36m__DW_OUTPUT_FORMATTER__.<locals>.DataWrangler.formatter\u001b[1;34m(cls, var, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformatter\u001b[39m(\u001b[38;5;28mcls\u001b[39m, var, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 227\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39m_repr_dw_()\n",
      "Cell \u001b[1;32mIn[2], line 221\u001b[0m, in \u001b[0;36m__DW_OUTPUT_FORMATTER__.<locals>.DataWrangler.__init__\u001b[1;34m(self, expr_val)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[0;32m    219\u001b[0m pandas_df, conversion_method \u001b[38;5;241m=\u001b[39m api[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas_transport\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m](expr_val)\n\u001b[0;32m    220\u001b[0m tmp_vars[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpandas_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;66;03m# create a shallow copy in case a displayed object is mutated in the same cell\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversion_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: conversion_method\n\u001b[0;32m    223\u001b[0m }\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((30.52777 59.87007, 30.52777 59.86987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((30.52777 59.86987, 30.52777 59.87007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((30.52519 59.86975, 30.52539 59.86975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((30.55217 59.86873, 30.55246 59.86873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((30.53435 59.86841, 30.53444 59.86841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>POLYGON ((30.53425 59.83231, 30.53415 59.83231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>POLYGON ((30.52138 59.83868, 30.52129 59.83868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>POLYGON ((30.59230 59.84797, 30.59230 59.84804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>POLYGON ((30.58563 59.82308, 30.58563 59.82314...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>POLYGON ((30.58620 59.82321, 30.58620 59.82327...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>659 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              geometry\n",
       "0    POLYGON ((30.52777 59.87007, 30.52777 59.86987...\n",
       "1    POLYGON ((30.52777 59.86987, 30.52777 59.87007...\n",
       "2    POLYGON ((30.52519 59.86975, 30.52539 59.86975...\n",
       "3    POLYGON ((30.55217 59.86873, 30.55246 59.86873...\n",
       "4    POLYGON ((30.53435 59.86841, 30.53444 59.86841...\n",
       "..                                                 ...\n",
       "654  POLYGON ((30.53425 59.83231, 30.53415 59.83231...\n",
       "655  POLYGON ((30.52138 59.83868, 30.52129 59.83868...\n",
       "656  POLYGON ((30.59230 59.84797, 30.59230 59.84804...\n",
       "657  POLYGON ((30.58563 59.82308, 30.58563 59.82314...\n",
       "658  POLYGON ((30.58620 59.82321, 30.58620 59.82327...\n",
       "\n",
       "[659 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pzz.to_file('ffg.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
